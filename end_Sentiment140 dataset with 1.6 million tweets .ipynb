{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import gensim #word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM \n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voir les variables déclarées\n",
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = [\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\"]\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = \"latin-1\", names = names)\n",
    "print(\"Dataset size :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map target label to String\n",
    "- 0 -> NEGATIVE\n",
    "- 2 -> NEUTRAL\n",
    "- 4 -> POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decode_map = {0 : \"NEGATIVE\",2 : \"NEUTRAL\", 4 : \"POSITIVE\"}\n",
    "df.target = df.target.apply(lambda x : decode_map[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.bar(target_cnt.keys(),target_cnt.values())\n",
    "plt.title(\"Dataset labels distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stopwords might reduce the model performance. Some words like 'not' are included in stopwords and ignoring them will make sentences like 'this was good' and 'this was not good' have same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.remove(\"not\") \n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text,stem = False) :\n",
    "    pattern = r'@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+' #r'@\\S+|http\\S+|[^A-Za-z0-9]+' \n",
    "    text = re.sub(pattern, \" \",str(text).lower()).strip()\n",
    "    text = \" \".join([text_ for text_ in text.split() if text_ not in stop_words])\n",
    "    if stem :\n",
    "        \n",
    "        text = \" \".join([stemmer.stem(text_) for text_ in text.split()])\n",
    "    \n",
    "    return text\n",
    "    \n",
    "df.text = df.text.apply(lambda x : preprocess(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "print(\"Train size :\",len(df_train))\n",
    "print(\"Test size :\",len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec va nous servir pour la couche d'embedding, donc pas tout de suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = [_text.split() for _text in df_train.text]\n",
    "\n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "w2v_model = gensim.models.word2vec.Word2Vec(size = W2V_SIZE,\n",
    "                                           window = W2V_WINDOW,\n",
    "                                           min_count = W2V_MIN_COUNT,\n",
    "                                           workers = 8)\n",
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size :\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w2v_model.train(documents, total_examples = len(documents), epochs = W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text) #chaque mot est associé à un numéro, par exemple \"good\" : 65645\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 # +1 pour UNK words\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SEQUENCE_LENGTH = 300\n",
    "\n",
    "#on transforme chaque phrase en suite d'element indicé grace au tokenizer\n",
    "#on pad pour avoir la même longueur\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen = SEQUENCE_LENGTH) \n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text),maxlen = SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 c'est sentiment positive et 1 c'est sentiment négatif, il faut que chaque élément soit sous forme de liste [1] ou [0] pour que keras marche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on se sert de word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,W2V_SIZE)) #ligne de la matrice d'embedding sont les mots et les colonnes l'encodage du mot\n",
    "\n",
    "for word, i in tokenizer.word_index.items(): #tokenizer.word_index c'est le dico {mot : i for (mot,i) in enumerate(nombres_mots)}\n",
    "    if word in w2v_model.wv : #si le mot est dans le w2v construit\n",
    "        embedding_matrix[i] = w2v_model.wv[word] #on met à la ligne correspond au mot son encodage w2v\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE , weights = [embedding_matrix], \n",
    "                            input_length = SEQUENCE_LENGTH, trainable = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100,dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", \n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor=\"val_loss\", patience = 3, cooldown = 0),\n",
    "            EarlyStopping(monitor = \"val_acc\", min_delta = 1e-4, patience = 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size = BATCH_SIZE,\n",
    "                   epochs = EPOCHS,\n",
    "                   validation_split = 0.1,\n",
    "                   verbose = 1,\n",
    "                   callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "score = model.evaluate(x_test,y_test, batch_size = BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY :\",score[1])\n",
    "print(\"LOSS :\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label = 'Training acc' )\n",
    "plt.plot(epochs , val_acc,'r', label = 'validation_acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "SEQUENCE_LENGTH = 300\n",
    "def decode_sentiment(score, include_neutral = True):\n",
    "    if include_neutral : \n",
    "        label = \"NEUTRAL\"\n",
    "        if score <= SENTIMENT_THRESHOLDS[0] :\n",
    "            label = \"NEGATIVE\"\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1] :\n",
    "            label = \"POSITIVE\"\n",
    "        \n",
    "        return label\n",
    "    else : \n",
    "        return \"NEGATIVE\" if score < 0.5 else \"POSITIVE\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on doit preprocesser les phrases que l'on passe dans le modèle et cela nous permet de le faire\n",
    "def predict(text, include_neutral = True) : \n",
    "    start_at = time.time()\n",
    "    \n",
    "    #on doit tokenizer la phrase puis pad la séquences pour le passer dans notre modèle\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = SEQUENCE_LENGTH)\n",
    "    \n",
    "    score = model.predict([x_test])[0] #on trouve la probabilité associé\n",
    "    \n",
    "    label = decode_sentiment(score,include_neutral = include_neutral) #on la classe en positive ou négative\n",
    "    \n",
    "    return {\"label\" : label , \"score\": float(score),\n",
    "           \"elapsed time\": time.time()-start_at}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"I love the music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"I hate the rain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"i don't know what i'm doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The euroscepticism gain european countries\",include_neutral = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = model.predict(x_test, verbose = 1, batch_size = 8000) #donne une proba\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral = False) for score in scores] #transforme en positive/negative/neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title = 'Confusion matrix', cmap = plt.cm.Blues) : \n",
    "    \n",
    "    \"Print and plot the confusion matrix\"\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis= 1) [:,np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize = 30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 90, fontsize = 32)\n",
    "    plt.yticks(tick_marks, classes, fontsize = 22)\n",
    "    \n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])) :\n",
    "        plt.text(j,i, format(cm[i,j], fmt),\n",
    "                horizontalalignment = 'center',\n",
    "                color = \"white\" if cm[i,j] > thresh else \"black\") \n",
    "        \n",
    "    plt.ylabel(\"True label\", fontsize = 25)\n",
    "    plt.xlabel(\"Predict label\", fontsize = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d,y_pred_1d) #donne le résultat de la matrice \n",
    "plt.figure(figsize = (12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes = df_train.target.unique(), title = \"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are saved for use later.\n",
    "\n",
    "You can load the models and then use the predict function to predict sentiment for the text.\n",
    "\n",
    "Keep in mind that you need to preprocess the text and encode it before prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL,\"wb\"),protocol = 0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL,\"wb\"), protocol = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We charge the model and we continue to train the model, tokenizer, word2vec ect.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\"\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "tokenizer = pickle.load(open(TOKENIZER_MODEL,\"rb\"))\n",
    "encoder = pickle.load(open(ENCODER_MODEL,\"rb\"))\n",
    "w2v_model = Word2Vec.load(\"model.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The country is losing a lot of money unfortunately\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"UAE is in good shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"How the EU is helping railways ride out Covid-19\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"France chaos: Macron faces Frexit demands after EU 'abandoned' states during pandemic\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintenant il faut prédire les tweets de mon dataset et voir comment ça marche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"sentiment_analysis_english.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "SEQUENCE_LENGTH = 300\n",
    "def decode_sentiment_test(score, include_neutral = True):\n",
    "    if include_neutral : \n",
    "        label = 2\n",
    "        if score <= SENTIMENT_THRESHOLDS[0] :\n",
    "            label = 0\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1] :\n",
    "            label = 4\n",
    "        \n",
    "        return label\n",
    "    else : \n",
    "        return 0 if score < 0.5 else 4\n",
    "    \n",
    "    \n",
    "def predict_test(text, include_neutral = True) : \n",
    "    start_at = time.time()\n",
    "    \n",
    "    #on doit tokenizer la phrase puis pad la séquences pour le passer dans notre modèle\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = SEQUENCE_LENGTH)\n",
    "    \n",
    "    score = model.predict([x_test])[0] #on trouve la probabilité associé\n",
    "    \n",
    "    label = decode_sentiment_test(score,include_neutral = include_neutral) #on la classe en positive ou négative\n",
    "    \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test(df_test['text'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('I am fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total = 0\n",
    "\n",
    "for i in range(250):\n",
    "    predicted = predict_test(df_test['text'].iloc[i])\n",
    "    if df_test['label'].iloc[i] == predicted:\n",
    "        Good_predictions_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.2, 0.8)\n",
    "SEQUENCE_LENGTH = 300\n",
    "def decode_sentiment_test(score, include_neutral = True):\n",
    "    if include_neutral : \n",
    "        label = 2\n",
    "        if score <= SENTIMENT_THRESHOLDS[0] :\n",
    "            label = 0\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1] :\n",
    "            label = 4\n",
    "        \n",
    "        return label\n",
    "    else : \n",
    "        return 0 if score < 0.5 else 4\n",
    "    \n",
    "    \n",
    "def predict_test(text, include_neutral = True) : \n",
    "    start_at = time.time()\n",
    "    \n",
    "    #on doit tokenizer la phrase puis pad la séquences pour le passer dans notre modèle\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = SEQUENCE_LENGTH)\n",
    "    \n",
    "    score = model.predict([x_test])[0] #on trouve la probabilité associé\n",
    "    \n",
    "    label = decode_sentiment_test(score,include_neutral = include_neutral) #on la classe en positive ou négative\n",
    "    \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total = 0\n",
    "\n",
    "predicted_list = []\n",
    "\n",
    "for i in range(250):\n",
    "    predicted = predict_test(df_test['text'].iloc[i])\n",
    "    predicted_list.append(predicted)\n",
    "    if df_test['label'].iloc[i] == predicted:\n",
    "        Good_predictions_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test['label'], predicted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame()\n",
    "df_f['text'] =df_test.text\n",
    "df_f['label'] =df_test.label\n",
    "df_f['pred'] =predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_f[df_f.label != df_f.pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('I am happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('I am angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('what are you talking about ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('I have to be fine, but actually I am not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('We are not safe anymore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test('We are not safe anymore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.2, 0.85)\n",
    "SEQUENCE_LENGTH = 300\n",
    "def decode_sentiment_test(score, include_neutral = True):\n",
    "    if include_neutral : \n",
    "        label = 2\n",
    "        if score <= SENTIMENT_THRESHOLDS[0] :\n",
    "            label = 0\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1] :\n",
    "            label = 4\n",
    "        \n",
    "        return label\n",
    "    else : \n",
    "        return 0 if score < 0.5 else 4\n",
    "    \n",
    "    \n",
    "def predict_test(text, include_neutral = True) : \n",
    "    start_at = time.time()\n",
    "    \n",
    "    #on doit tokenizer la phrase puis pad la séquences pour le passer dans notre modèle\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = SEQUENCE_LENGTH)\n",
    "    \n",
    "    score = model.predict([x_test])[0] #on trouve la probabilité associé\n",
    "    \n",
    "    label = decode_sentiment_test(score,include_neutral = include_neutral) #on la classe en positive ou négative\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total = 0\n",
    "\n",
    "for i in range(250):\n",
    "    predicted = predict_test(df_test['text'].iloc[i])\n",
    "    if df_test['label'].iloc[i] == predicted:\n",
    "        Good_predictions_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_predictions_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator\n",
    "\n",
    "from googletrans import Translator, constants\n",
    "from pprint import pprint\n",
    "\n",
    "# init the Google API translator\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "translation = translator.translate(\"والله من الضروري يكون فيه اصلاحات عشان المواطن يتنفس شوي دخيل الله ، الرواتب م تكفى تفاقم الاسعار اللي حاصل كيف ، و العالم ف تطور و نهضه اجتماعيه و اقتصاديه و محليه و اغلب الرواتب ٤٠٠٠ ريال م تعيش فرد ف ما بالك عوائل عايشه ع كذا ، الله المستعان ..\", dest=\"en\", src=\"ar\")\n",
    "print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translator.translate(\"العراق لو استغل موارده الطبيعية فقط دون إصلاحات اقتصادية مستدامه لكان قائدًا لاهم منطقة في العالم وهي الشرق الاوسط ، اجتمع غباء سياسييه مع غدر جيرانه ايران وتركيا .. حالهم مؤسف واقصى امانيهم كهرباء تعمل لنصف يوم فقط !\", dest=\"en\", src=\"ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_THRESHOLDS = (0.37, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
